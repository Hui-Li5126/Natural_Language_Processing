{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/\n",
    "#https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(os.path.join(\"dataset\",\"train_E6oV3lV.csv\"))\n",
    "#train['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a is and is so he his into his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>for i they don't in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>i with all the in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0   @user when a father is dysfunctional and is s...   \n",
       "1  @user @user thanks for #lyft credit i can't us...   \n",
       "2                                bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                             stopwords  \n",
       "0  when a is and is so he his into his  \n",
       "1                  for i they don't in  \n",
       "2                                 your  \n",
       "3                    i with all the in  \n",
       "4                                  now  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "train['stopwords']=train['tweet'].apply(lambda x: ' '.join(word for word in x.split() if word in stop))\n",
    "train[['tweet','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     user when a father is dysfunctional and is so...\n",
       "1    user user thanks for lyft credit i cant use ca...\n",
       "2                                  bihday your majesty\n",
       "3    model   i love u take with u all the time in u...\n",
       "4                 factsguide society now    motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet']=train['tweet'].str.replace('[^\\w\\s]','')    #remove any starting word characters and whitespace \n",
    "train['tweet'].head()       #\\d, \\w, \\s shorthand character classes matching digits, word characters, and whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "train['tweet']=train['tweet'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find 50 most common words\n",
    "haha=pd.Series(' '.join(train['tweet']).split()).value_counts()[:50]\n",
    "haha.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most common 50 words\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.barplot(x=haha.index, \n",
    "            y=haha.values)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "plt.figure(figsize=(16,13))\n",
    "wc = WordCloud(background_color=\"white\", max_words=10000, \n",
    "                stopwords=STOPWORDS, max_font_size= 40)\n",
    "wc.generate(\"tweet wordcloud\".join(train['tweet']))\n",
    "plt.title(\"\", fontsize=20)\n",
    "\n",
    "plt.imshow(wc.recolor( colormap= 'Pastel2' , random_state=17))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize \n",
    "from nltk import word_tokenize\n",
    "train['tokenized_text'] = train[\"tweet\"].apply(lambda row: word_tokenize(row))\n",
    "train[['tweet','tokenized_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train['tweet_lemm']=train['tweet'].apply(lambda x: \" \".join(lemmatizer.lemmatize(w) for w in x.split()))\n",
    "#train['tweet_lemm']=train['tokenized_text'].apply(lambda x: \" \".join(lemmatizer.lemmatize(w) for w in x)) \n",
    "train['tweet_lemm'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "string = \"I really like python, it's pretty awesome.\"\n",
    "string_bigrams = bigrams(string.split())\n",
    "for grams in string_bigrams:\n",
    "    print(grams)   #what do we do with bigrams or n grams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_features=1000, lowercase=True, stop_words='english')\n",
    "train_bow=cv.fit_transform(train['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user user thanks lyft credit cant use cause do...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model love u take u time urð ðððð ððð</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  user father dysfunctional selfish drags kids d...       -0.5\n",
       "1  user user thanks lyft credit cant use cause do...        0.2\n",
       "2                                     bihday majesty        0.0\n",
       "3              model love u take u time urð ðððð ððð        0.5\n",
       "4                      factsguide society motivation        0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment Analyss\n",
    "from textblob import TextBlob\n",
    "train['sentiment']=train['tweet'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "train[['tweet','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Topic modeling\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda=LatentDirichletAllocation(n_components=10, learning_method=\"batch\", max_iter=25, random_state=0)\n",
    "document_topics=lda.fit_transform(train_bow)\n",
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting=np.argsort(lda.components_, axis=1)[:,::-1]\n",
    "feature_names=np.array(cv.get_feature_names())\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "user          day           people        love          happy         \n",
      "amp           fathers       need          time          smile         \n",
      "positive      good          friday        ððð           weekend       \n",
      "make          great         makes         life          love          \n",
      "affirmation   today         bear          want          summer        \n",
      "i_am          morning       world         ðððð          friends       \n",
      "thanks        tomorrow      polar         model         fun           \n",
      "2016          fathersday    climb         bull          family        \n",
      "ready         love          change        live          sunday        \n",
      "getting       happy         city          urð           cute          \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "new           user          sad           healthy       like          \n",
      "bihday        thankful      orlando       love          work          \n",
      "days          dont          way           life          feel          \n",
      "ðð            positive      trump         happiness     im            \n",
      "music         im            finally       best          blog          \n",
      "home          think         know          altwaystoheal right         \n",
      "little        really        old           peace         gold          \n",
      "wait          today         looking       blessed       silver        \n",
      "im            yes           news          happy         got           \n",
      "happy         got           people        help          forex         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mglearn.tools.print_topics(topics=range(10),feature_names=feature_names,sorting=sorting,topics_per_chunk=5, n_words=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
